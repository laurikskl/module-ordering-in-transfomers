@Manual{example,
    title = {example referance},
    author = {Firstname Lastname},
    year = {1900},
}

[1] A. Katharopoulos, A. Vyas, N. Pappas, and F. Fleuret, “Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention.” arXiv, Aug. 31, 2020. doi: 10.48550/arXiv.2006.16236.
[2] Z. Dai, Z. Yang, Y. Yang, J. Carbonell, Q. V. Le, and R. Salakhutdinov, “Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context.” arXiv, Jun. 02, 2019. doi: 10.48550/arXiv.1901.02860.
